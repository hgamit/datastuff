{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370454, 15)\n",
      "(370222, 15)\n",
      "(370216, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(370216, 77)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Loading the dataset\n",
    "dataset = pd.read_csv(\"input/ks-projects-201801.csv\")\n",
    "dataset=dataset[(dataset['state'] == 'failed')|(dataset['state']=='canceled') | (dataset['state'] == 'successful')]\n",
    "print(dataset.shape)\n",
    "dataset.drop(dataset.index[dataset['country'] == 'N,0\"'], inplace = True)\n",
    "print(dataset.shape)\n",
    "dataset.drop(dataset.index[dataset['launched'] == '1970-01-01 01:00:00'], inplace = True)\n",
    "print(dataset.shape)\n",
    "\n",
    "onehotcurrency = pd.get_dummies(dataset['currency'])\n",
    "dataset = onehotcurrency.join(dataset)\n",
    "#dataset.shape\n",
    "\n",
    "onehotcountry = pd.get_dummies(dataset['country'])\n",
    "dataset = onehotcountry.join(dataset)\n",
    "#dataset.shape\n",
    "\n",
    "onehotmaincategory = pd.get_dummies(dataset['main_category'])\n",
    "dataset = onehotmaincategory.join(dataset)\n",
    "#dataset.shape\n",
    "\n",
    "onehotstate = pd.get_dummies(dataset['state'])\n",
    "dataset = onehotstate.join(dataset)\n",
    "#dataset.shape\n",
    "\n",
    "dataset['launched'] = pd.to_datetime(dataset['launched'])\n",
    "dataset['laun_month_year'] = dataset['launched'].dt.to_period(\"M\")\n",
    "dataset['laun_day_month_year'] = dataset['launched'].dt.to_period(\"D\")\n",
    "dataset['laun_year'] = dataset['launched'].dt.to_period(\"A\")\n",
    "dataset['laun_hour'] = dataset['launched'].dt.hour\n",
    "\n",
    "dataset['deadline'] = pd.to_datetime(dataset['deadline'])\n",
    "dataset['dead_month_year'] = dataset['deadline'].dt.to_period(\"M\")\n",
    "dataset['dead_day_month_year'] = dataset['deadline'].dt.to_period(\"D\")\n",
    "dataset['dead_year'] = dataset['deadline'].dt.to_period(\"A\")\n",
    "\n",
    "\n",
    "#Creating a new columns with Campaign total months\n",
    "#dataset['time_campaign'] = dataset['dead_month_year'] - dataset['laun_month_year']\n",
    "dataset['time_campaign'] = (((dataset.dead_day_month_year - dataset.laun_day_month_year)/np.timedelta64(1, 'M'))).astype(int)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 370216 entries, 0 to 378660\n",
      "Data columns (total 77 columns):\n",
      "canceled               370216 non-null uint8\n",
      "failed                 370216 non-null uint8\n",
      "successful             370216 non-null uint8\n",
      "Art                    370216 non-null uint8\n",
      "Comics                 370216 non-null uint8\n",
      "Crafts                 370216 non-null uint8\n",
      "Dance                  370216 non-null uint8\n",
      "Design                 370216 non-null uint8\n",
      "Fashion                370216 non-null uint8\n",
      "Film & Video           370216 non-null uint8\n",
      "Food                   370216 non-null uint8\n",
      "Games                  370216 non-null uint8\n",
      "Journalism             370216 non-null uint8\n",
      "Music                  370216 non-null uint8\n",
      "Photography            370216 non-null uint8\n",
      "Publishing             370216 non-null uint8\n",
      "Technology             370216 non-null uint8\n",
      "Theater                370216 non-null uint8\n",
      "AT                     370216 non-null uint8\n",
      "AU                     370216 non-null uint8\n",
      "BE                     370216 non-null uint8\n",
      "CA                     370216 non-null uint8\n",
      "CH                     370216 non-null uint8\n",
      "DE                     370216 non-null uint8\n",
      "DK                     370216 non-null uint8\n",
      "ES                     370216 non-null uint8\n",
      "FR                     370216 non-null uint8\n",
      "GB                     370216 non-null uint8\n",
      "HK                     370216 non-null uint8\n",
      "IE                     370216 non-null uint8\n",
      "IT                     370216 non-null uint8\n",
      "JP                     370216 non-null uint8\n",
      "LU                     370216 non-null uint8\n",
      "MX                     370216 non-null uint8\n",
      "NL                     370216 non-null uint8\n",
      "NO                     370216 non-null uint8\n",
      "NZ                     370216 non-null uint8\n",
      "SE                     370216 non-null uint8\n",
      "SG                     370216 non-null uint8\n",
      "US                     370216 non-null uint8\n",
      "AUD                    370216 non-null uint8\n",
      "CAD                    370216 non-null uint8\n",
      "CHF                    370216 non-null uint8\n",
      "DKK                    370216 non-null uint8\n",
      "EUR                    370216 non-null uint8\n",
      "GBP                    370216 non-null uint8\n",
      "HKD                    370216 non-null uint8\n",
      "JPY                    370216 non-null uint8\n",
      "MXN                    370216 non-null uint8\n",
      "NOK                    370216 non-null uint8\n",
      "NZD                    370216 non-null uint8\n",
      "SEK                    370216 non-null uint8\n",
      "SGD                    370216 non-null uint8\n",
      "USD                    370216 non-null uint8\n",
      "ID                     370216 non-null int64\n",
      "name                   370213 non-null object\n",
      "category               370216 non-null object\n",
      "main_category          370216 non-null object\n",
      "currency               370216 non-null object\n",
      "deadline               370216 non-null datetime64[ns]\n",
      "goal                   370216 non-null float64\n",
      "launched               370216 non-null datetime64[ns]\n",
      "pledged                370216 non-null float64\n",
      "state                  370216 non-null object\n",
      "backers                370216 non-null int64\n",
      "country                370216 non-null object\n",
      "usd pledged            370216 non-null float64\n",
      "usd_pledged_real       370216 non-null float64\n",
      "usd_goal_real          370216 non-null float64\n",
      "laun_month_year        370216 non-null period[M]\n",
      "laun_day_month_year    370216 non-null period[D]\n",
      "laun_year              370216 non-null period[A-DEC]\n",
      "laun_hour              370216 non-null int64\n",
      "dead_month_year        370216 non-null period[M]\n",
      "dead_day_month_year    370216 non-null period[D]\n",
      "dead_year              370216 non-null period[A-DEC]\n",
      "time_campaign          370216 non-null object\n",
      "dtypes: datetime64[ns](2), float64(5), int64(3), object(7), period[A-DEC](2), period[D](2), period[M](2), uint8(54)\n",
      "memory usage: 96.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canceled</th>\n",
       "      <th>failed</th>\n",
       "      <th>successful</th>\n",
       "      <th>Art</th>\n",
       "      <th>Comics</th>\n",
       "      <th>Crafts</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Design</th>\n",
       "      <th>Fashion</th>\n",
       "      <th>Film &amp; Video</th>\n",
       "      <th>...</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>laun_month_year</th>\n",
       "      <th>laun_day_month_year</th>\n",
       "      <th>laun_year</th>\n",
       "      <th>laun_hour</th>\n",
       "      <th>dead_month_year</th>\n",
       "      <th>dead_day_month_year</th>\n",
       "      <th>dead_year</th>\n",
       "      <th>time_campaign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "      <td>2015-08</td>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>2015</td>\n",
       "      <td>&lt;2 * MonthEnds&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>&lt;2 * MonthEnds&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-02</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>2013</td>\n",
       "      <td>&lt;MonthEnd&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>2012-03</td>\n",
       "      <td>2012-03-17</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-04</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>2012</td>\n",
       "      <td>&lt;MonthEnd&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-08</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>2015</td>\n",
       "      <td>&lt;MonthEnd&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   canceled  failed  successful  Art  Comics  Crafts  Dance  Design  Fashion  \\\n",
       "0         0       1           0    0       0       0      0       0        0   \n",
       "1         0       1           0    0       0       0      0       0        0   \n",
       "2         0       1           0    0       0       0      0       0        0   \n",
       "3         0       1           0    0       0       0      0       0        0   \n",
       "4         1       0           0    0       0       0      0       0        0   \n",
       "\n",
       "   Film & Video  ...  usd_pledged_real  usd_goal_real  laun_month_year  \\\n",
       "0             0  ...               0.0        1533.95          2015-08   \n",
       "1             1  ...            2421.0       30000.00          2017-09   \n",
       "2             1  ...             220.0       45000.00          2013-01   \n",
       "3             0  ...               1.0        5000.00          2012-03   \n",
       "4             1  ...            1283.0       19500.00          2015-07   \n",
       "\n",
       "   laun_day_month_year  laun_year  laun_hour  dead_month_year  \\\n",
       "0           2015-08-11       2015         12          2015-10   \n",
       "1           2017-09-02       2017          4          2017-11   \n",
       "2           2013-01-12       2013          0          2013-02   \n",
       "3           2012-03-17       2012          3          2012-04   \n",
       "4           2015-07-04       2015          8          2015-08   \n",
       "\n",
       "   dead_day_month_year  dead_year    time_campaign  \n",
       "0           2015-10-09       2015  <2 * MonthEnds>  \n",
       "1           2017-11-01       2017  <2 * MonthEnds>  \n",
       "2           2013-02-26       2013       <MonthEnd>  \n",
       "3           2012-04-16       2012       <MonthEnd>  \n",
       "4           2015-08-29       2015       <MonthEnd>  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canceled                    2\n",
      "failed                      2\n",
      "successful                  2\n",
      "Art                         2\n",
      "Comics                      2\n",
      "Crafts                      2\n",
      "Dance                       2\n",
      "Design                      2\n",
      "Fashion                     2\n",
      "Film & Video                2\n",
      "Food                        2\n",
      "Games                       2\n",
      "Journalism                  2\n",
      "Music                       2\n",
      "Photography                 2\n",
      "Publishing                  2\n",
      "Technology                  2\n",
      "Theater                     2\n",
      "AT                          2\n",
      "AU                          2\n",
      "BE                          2\n",
      "CA                          2\n",
      "CH                          2\n",
      "DE                          2\n",
      "DK                          2\n",
      "ES                          2\n",
      "FR                          2\n",
      "GB                          2\n",
      "HK                          2\n",
      "IE                          2\n",
      "                        ...  \n",
      "JPY                         2\n",
      "MXN                         2\n",
      "NOK                         2\n",
      "NZD                         2\n",
      "SEK                         2\n",
      "SGD                         2\n",
      "USD                         2\n",
      "ID                     370216\n",
      "name                   367466\n",
      "category                  159\n",
      "main_category              15\n",
      "currency                   14\n",
      "deadline                 3147\n",
      "goal                     8233\n",
      "launched               369666\n",
      "pledged                 61556\n",
      "state                       3\n",
      "backers                  3940\n",
      "country                    22\n",
      "usd pledged             94707\n",
      "usd_pledged_real       104287\n",
      "usd_goal_real           49309\n",
      "laun_month_year           106\n",
      "laun_day_month_year      3165\n",
      "laun_year                  10\n",
      "laun_hour                  24\n",
      "dead_month_year           106\n",
      "dead_day_month_year      3147\n",
      "dead_year                  10\n",
      "time_campaign               5\n",
      "Length: 77, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X= pd.concat([dataset.ix[:,3:55],dataset.ix[:,64:65], dataset.ix[:,67:69], dataset.ix[:,76:]], axis=1)\n",
    "y = dataset.iloc[:,63]\n",
    "\n",
    "#print(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X= StandardScaler()\n",
    "X_train= sc_X.fit_transform(X_train)\n",
    "X_test= sc_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Elimination\n",
    "import statsmodels.formula.api as sm \n",
    "\n",
    "df_feat[[c for c in df_feat.columns if c != \"name\"]].head()\n",
    "X= pd.concat([dataset.ix[:,3:55],dataset.ix[:,64:65], dataset.ix[:,67:69], dataset.ix[:,76:]], axis=1)\n",
    "y = dataset.iloc[:,63]\n",
    "#features = [c for c in X.columns if c not in [\"state\", \"name\", \"ID\",\"category\",\"main_category\",\"goal\",\"launched\",\"country\",\"usd pledged,\"pledged\",\"usd_pledged_real\",\"diff_pledged_goal_real\"]]\n",
    "#X = X[features] # choosing initial features\n",
    "\n",
    "cols = list(X.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X = X[cols]\n",
    "    X_1 = np.append(arr=np.ones((X.shape[0],1)).astype(int), values=X, axis=1) #Adding constant column of ones, mandatory for sm.OLS model\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmnshu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/hmnshu/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7813384618709078"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifierObj= LogisticRegression(random_state=0)\n",
    "classifierObj.fit(X_train, y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "classifierObj.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifierObj= KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "classifierObj.fit(X_train, y_train) \n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "classifierObj.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "#Default kernel it uses is RBF, which is a gaussian kernel. For now we will specify that we want to use a “linear” kernel. \n",
    "from sklearn.svm import SVC\n",
    "classifierObj= SVC(kernel='linear')\n",
    "classifierObj.fit(X_train, y_train) \n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "classifierObj.score(X_test,y_test)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#modelAccuracies= cross_val_score(estimator=classifierObj, X=X_train, y=y_train, cv=10)\n",
    "#print(modelAccuracies.mean())\n",
    "#print(modelAccuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.svm import SVC\n",
    "classifierObj= SVC()\n",
    "#try different degrees of polynomial kernels\n",
    "#classifierObj= SVC(kernel='poly', degree=3)\n",
    "#classifierObj=SVC(kernel='sigmoid')\n",
    "classifierObj.fit(X_train, y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "classifierObj.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifierObj= GaussianNB()\n",
    "classifierObj.fit(X_train, y_train) \n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "classifierObj.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifierObj= DecisionTreeClassifier(criterion='entropy')\n",
    "classifierObj.fit(X_train,y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "classifierObj.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmnshu/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8607839747606802"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifierObj= RandomForestClassifier(criterion='entropy')\n",
    "classifierObj.fit(X_train,y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "classifierObj.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwang2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "#Applying LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "ldaObj= LDA(n_components=55)\n",
    "X_train= ldaObj.fit_transform(X_train,y_train)\n",
    "X_test= ldaObj.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwang2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.713816500280911"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifierObj= RandomForestClassifier(criterion='entropy')\n",
    "classifierObj.fit(X_train,y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "classifierObj.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwang2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\jwang2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.571394615151908"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifierObj= LogisticRegression(random_state=0)\n",
    "classifierObj.fit(X_train, y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred= classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "classifierObj.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pcaObj= PCA(n_components=None)\n",
    "X_train= pcaObj.fit_transform(X_train)\n",
    "X_test= pcaObj.transform(X_test)\n",
    "components_variance= pcaObj.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
