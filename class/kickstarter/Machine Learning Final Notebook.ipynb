{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('input/ks-projects-201801.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing unique values in each columns of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the percentage of each categories in our class label \"state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Success_dist = df[\"state\"].value_counts() / len(df[\"state\"]) * 100\n",
    "\n",
    "print(\"Success_dist in %: \")\n",
    "print(Success_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping all the rows where state labels are undefined, live and suspended since there percentage in the datacet is really less. Also considering the canceled projects as failed project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state(df):\n",
    "    df.state.value_counts()\n",
    "    df = df[df.state!='undefined']\n",
    "    df = df[df.state!='live']\n",
    "    df = df[df.state!='suspended']\n",
    "    df['state']=df['state'].replace({'canceled':'failed'})\n",
    "    return df\n",
    "df = convert_state(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for NAN's in each columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping unnecessary columns ID,Name(since it does not contribute to a project's failure or success), category(since we already have the main category), currency(same contribution as the country, so keeping only country), usd_pledged(since it has 232 na's and usd_pledged_real have the similar data as usd_pledged)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('name',axis=1)\n",
    "df = df.drop('ID',axis=1)\n",
    "df = df.drop('category',axis=1)\n",
    "df = df.drop(['usd pledged'], axis=1)\n",
    "df = df.drop(['currency'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data cleaning - Removing rows with 'NaN' value and Removing rows with N,0\" in country column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df = df[df.country!='N,0\"']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the duration of each project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import datetime\n",
    "df['deadline_year'] = df['deadline'].str[0:4]\n",
    "df['deadline_month']= df['deadline'].str[5:7]\n",
    "df['launched_year'] = df['launched'].str[0:4]\n",
    "df['launched_month'] = df['launched'].str[5:7]\n",
    "df['deadline_year'] = df['deadline_year'].astype(int)\n",
    "df['deadline_month'] = df['deadline_month'].astype(int)\n",
    "df['launched_year'] = df['launched_year'].astype(int)\n",
    "df['launched_month'] = df['launched_month'].astype(int)\n",
    "df['duration_proj(in months)'] = (df['deadline_year']-df['launched_year'])*12 + (df['deadline_month']-df['launched_month'])\n",
    "df = df.drop('deadline_year',axis=1)\n",
    "df = df.drop('deadline_month',axis=1)\n",
    "df = df.drop('launched_year',axis=1)\n",
    "df = df.drop('launched_month',axis=1)\n",
    "df = df.drop('launched',axis=1)\n",
    "df = df.drop('deadline',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying one hot encoding to categorical columns main_category and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = pd.get_dummies(df['main_category'])\n",
    "df = onehot.join(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = pd.get_dummies(df['country'])\n",
    "df = onehot.join(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying label encoding the class label - 'state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df[['state']]\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y.values.ravel())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the list of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using these columns minus 'main_category', 'state', 'country' as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['AT',\n",
    " 'AU',\n",
    " 'BE',\n",
    " 'CA',\n",
    " 'CH',\n",
    " 'DE',\n",
    " 'DK',\n",
    " 'ES',\n",
    " 'FR',\n",
    " 'GB',\n",
    " 'HK',\n",
    " 'IE',\n",
    " 'IT',\n",
    " 'JP',\n",
    " 'LU',\n",
    " 'MX',\n",
    " 'NL',\n",
    " 'NO',\n",
    " 'NZ',\n",
    " 'SE',\n",
    " 'SG',\n",
    " 'US',\n",
    " 'Art',\n",
    " 'Comics',\n",
    " 'Crafts',\n",
    " 'Dance',\n",
    " 'Design',\n",
    " 'Fashion',\n",
    " 'Film & Video',\n",
    " 'Food',\n",
    " 'Games',\n",
    " 'Journalism',\n",
    " 'Music',\n",
    " 'Photography',\n",
    " 'Publishing',\n",
    " 'Technology',\n",
    " 'Theater',\n",
    " 'goal',\n",
    " 'pledged',\n",
    " 'backers',\n",
    " 'usd_pledged_real',\n",
    " 'usd_goal_real',\n",
    " 'duration_proj(in months)']\n",
    "X = df[col]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing our data using ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn\n",
    "!pip install scipy\n",
    "from imblearn.over_sampling import ADASYN\n",
    "ad = ADASYN()\n",
    "X, y = ad.fit_sample(X, y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc_X = StandardScaler() \n",
    "X_train = sc_X.fit_transform(X_train) \n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "svd = decomposition.TruncatedSVD(n_components=38, algorithm='arpack')\n",
    "svd.fit(X_train)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "X_train = svd.transform(X_train)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "components_variance= svd.explained_variance_ratio_ \n",
    "print(components_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel PCA \n",
    "from sklearn.decomposition import KernelPCA \n",
    "kernelPCAObj= KernelPCA(n_components=43, kernel='rbf') \n",
    "X_train= kernelPCAObj.fit_transform(X_train) \n",
    "X_test= kernelPCAObj.transform(X_test) \n",
    "components_variance= pcaObj.explained_variance_ratio_ \n",
    "print(components_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying PCA //Instead check for Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#kernel PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "kernelPCAObj= KernelPCA(n_components=43, kernel='rbf')\n",
    "X_train= kernelPCAObj.fit_transform(X_train)\n",
    "X_test= kernelPCAObj.transform(X_test)\n",
    "components_variance= pcaObj.explained_variance_ratio_\n",
    "print(components_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pcaObj= PCA(n_components=43)\n",
    "X_train= pcaObj.fit_transform(X_train)\n",
    "X_test= pcaObj.transform(X_test)\n",
    "components_variance= pcaObj.explained_variance_ratio_\n",
    "print(components_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifierObj = RandomForestClassifier(criterion='entropy')\n",
    "classifierObj.fit(X_train,y_train)\n",
    "\n",
    "#Making predictions on the Test Set\n",
    "y_pred = classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Model accuracy -> model got correct results\n",
    "print(\"Accuracy of Random Forest model is: \")\n",
    "classifierObj.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifierKFoldObj = RandomForestClassifier(criterion='entropy')\n",
    "modelAccuracies= cross_val_score(estimator=classifierKFoldObj, X=X_train, y=y_train, cv=10)\n",
    "print(modelAccuracies.mean())\n",
    "print(modelAccuracies.std())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
