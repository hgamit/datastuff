{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['constants.py', 'CONTRIBUTING.md', 'gap-development.tsv', 'gap-test.tsv', 'gap-validation.tsv', 'gap_scorer.py', 'LICENSE', 'README.md', 'sample_submission_stage_1.csv', 'test_stage_1.tsv', 'test_stage_1.tsv.zip']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./gap\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2454, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting train data from github google repo\n",
    "\n",
    "gh_test = pd.read_csv(\"https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\", delimiter='\\t')\n",
    "gh_valid = pd.read_csv(\"https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv\", delimiter='\\t')\n",
    "train = pd.concat((gh_test, gh_valid)).rename(columns={'A': 'A_Noun', 'B': 'B_Noun'}).reset_index(drop=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./gap/test_stage_1.tsv\", delimiter='\\t').rename(columns={'A': 'A_Noun', 'B': 'B_Noun'})\n",
    "submission = pd.read_csv('./gap/sample_submission_stage_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace function\n",
    "def name_replace(s, r1, r2):\n",
    "    s = str(s).replace(r1,r2)\n",
    "#    for r3 in r1.split(' '):\n",
    "#        s = str(s).replace(r3,r2)\n",
    "    return s\n",
    "\n",
    "def dot_exist(s, poff, noff):\n",
    "    dot_list = [m.start() for m in re.finditer('\\.', s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def get_features(df):\n",
    "    df['char_count'] = df['Text'].apply(len)\n",
    "    df['word_count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "    df['word_density'] = df['char_count'] / (df['word_count']+1)\n",
    "    df['punctuation_count'] = df['Text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "    df['title_word_count'] = df['Text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "    df['upper_case_word_count'] = df['Text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "    df['section_min'] = df[['Pronoun-offset', 'A-offset', 'B-offset']].min(axis=1)\n",
    "    df['Pronoun-offset2'] = df['Pronoun-offset'] + df['Pronoun'].map(len)\n",
    "    df['A-offset2'] = df['A-offset'] + df['A_Noun'].map(len)\n",
    "    df['B-offset2'] = df['B-offset'] + df['B_Noun'].map(len)                               \n",
    "    df['section_max'] = df[['Pronoun-offset2', 'A-offset2', 'B-offset2']].max(axis=1)\n",
    "    #df['Text'] = df.apply(lambda r: name_replace(r['Text'], r['A_Noun'], 'anoun'), axis=1)\n",
    "    #df['Text'] = df.apply(lambda r: name_replace(r['Text'], r['B_Noun'], 'bnoun'), axis=1)\n",
    "    #df['A_count'] = df.Text.str.count(df['A_Noun'])\n",
    "    #df['B_count'] = df.Text.str.count(df['B_Noun'])\n",
    "    df['A-dist'] = (df['Pronoun-offset'] - df['A-offset']).abs()\n",
    "    df['B-dist'] = (df['Pronoun-offset'] - df['B-offset']).abs()\n",
    "    return(df)\n",
    "\n",
    "train = get_features(train)\n",
    "test = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def coref(row):\n",
    "    raw_text = row['clear'] \n",
    "    doc = nlp(raw_text)\n",
    "    return str(doc._.coref_clusters)\n",
    "\n",
    "def corefa(row):\n",
    "    raw_text = row['clear'] \n",
    "    doc = nlp(raw_text[row['A-offset']:])\n",
    "    return str(doc._.coref_clusters)\n",
    "\n",
    "def corefb(row):\n",
    "    raw_text = row['clear'] \n",
    "    doc = nlp(raw_text[row['B-offset']:])\n",
    "    return str(doc._.coref_clusters)\n",
    "\n",
    "\n",
    "# Apply a first round of text cleaning techniques\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clear(row):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = row['Text']\n",
    "    #text = text.lower()\n",
    "    text = re.sub('\\(.*?\\)', '', text)\n",
    "    #text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    #text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "#round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A_Noun</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B_Noun</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>Upon their acceptance into the Kontinental Hockey League, Dehner left Finland to sign a contract in Germany with EHC M*nchen of the DEL on June 18...</td>\n",
       "      <td>His</td>\n",
       "      <td>383</td>\n",
       "      <td>Bob Suter</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "      <td>Dehner</td>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-2</td>\n",
       "      <td>Between the years 1979-1981, River won four local titles, and became one of the most expensive teams in the world, with a first team (Alonso- Luqu...</td>\n",
       "      <td>him</td>\n",
       "      <td>430</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>353</td>\n",
       "      <td>True</td>\n",
       "      <td>Alfredo Di St*fano</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-3</td>\n",
       "      <td>Though his emigration from the country has affected his leadership status, Kamel is still a respected elder of the clan. After the fall of Hussien...</td>\n",
       "      <td>He</td>\n",
       "      <td>312</td>\n",
       "      <td>Ali Aladhadh</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>Saddam</td>\n",
       "      <td>295</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test-4</td>\n",
       "      <td>At the trial, Pisciotta said: ``Those who have made promises to us are called Bernardo Mattarella, Prince Alliata, the monarchist MP Marchesano an...</td>\n",
       "      <td>his</td>\n",
       "      <td>526</td>\n",
       "      <td>Alliata</td>\n",
       "      <td>377</td>\n",
       "      <td>False</td>\n",
       "      <td>Pisciotta</td>\n",
       "      <td>536</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test-5</td>\n",
       "      <td>It is about a pair of United States Navy shore patrollers (SPs) (Tom Berenger and William McNamara) who must escort a beautiful prisoner (Erika El...</td>\n",
       "      <td>his</td>\n",
       "      <td>406</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>421</td>\n",
       "      <td>True</td>\n",
       "      <td>Rock Reilly</td>\n",
       "      <td>559</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Chasers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  \\\n",
       "0  test-1   \n",
       "1  test-2   \n",
       "2  test-3   \n",
       "3  test-4   \n",
       "4  test-5   \n",
       "\n",
       "                                                                                                                                                    Text  \\\n",
       "0  Upon their acceptance into the Kontinental Hockey League, Dehner left Finland to sign a contract in Germany with EHC M*nchen of the DEL on June 18...   \n",
       "1  Between the years 1979-1981, River won four local titles, and became one of the most expensive teams in the world, with a first team (Alonso- Luqu...   \n",
       "2  Though his emigration from the country has affected his leadership status, Kamel is still a respected elder of the clan. After the fall of Hussien...   \n",
       "3  At the trial, Pisciotta said: ``Those who have made promises to us are called Bernardo Mattarella, Prince Alliata, the monarchist MP Marchesano an...   \n",
       "4  It is about a pair of United States Navy shore patrollers (SPs) (Tom Berenger and William McNamara) who must escort a beautiful prisoner (Erika El...   \n",
       "\n",
       "  Pronoun  Pronoun-offset        A_Noun  A-offset  A-coref  \\\n",
       "0     His             383     Bob Suter       352    False   \n",
       "1     him             430        Alonso       353     True   \n",
       "2      He             312  Ali Aladhadh       256     True   \n",
       "3     his             526       Alliata       377    False   \n",
       "4     his             406         Eddie       421     True   \n",
       "\n",
       "               B_Noun  B-offset  B-coref  \\\n",
       "0              Dehner       366     True   \n",
       "1  Alfredo Di St*fano       390    False   \n",
       "2              Saddam       295    False   \n",
       "3           Pisciotta       536     True   \n",
       "4         Rock Reilly       559    False   \n",
       "\n",
       "                                              URL  \n",
       "0      http://en.wikipedia.org/wiki/Jeremy_Dehner  \n",
       "1    http://en.wikipedia.org/wiki/Norberto_Alonso  \n",
       "2           http://en.wikipedia.org/wiki/Aladhadh  \n",
       "3  http://en.wikipedia.org/wiki/Gaspare_Pisciotta  \n",
       "4            http://en.wikipedia.org/wiki/Chasers  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatest = train.head()\n",
    "datatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref</th>\n",
       "      <th>corefa</th>\n",
       "      <th>corefb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[he: [he, His]]</td>\n",
       "      <td>[Bob Suter: [Bob Suter, His]]</td>\n",
       "      <td>[Dehner's uncles: [Dehner's uncles, His]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Kamel: [his, his, Kamel], the clan: [the clan, the clan], Saddam: [Saddam, He, his, his]]</td>\n",
       "      <td>[Ali Aladhadh: [Ali Aladhadh, He, his, his]]</td>\n",
       "      <td>[Saddam: [Saddam, He, his, his]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the massacre of Portella di Ginestra: [the massacre of Portella di Ginestra, the massacre], Giuliano: [Giuliano, Giuliano, Giuliano], a trial whi...</td>\n",
       "      <td>[Alliata and Marchesano: [Alliata and Marchesano, their], a trial which dealt with their alleged role in the event: [a trial which dealt with thei...</td>\n",
       "      <td>[Pisciotta: [Pisciotta, he], Giuliano: [Giuliano, Giuliano]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Eddie Devane  : [Eddie Devane  , his, his, his]]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                   coref  \\\n",
       "0                                                                                                                                        [he: [he, His]]   \n",
       "1                                                                                                                                                   None   \n",
       "2                                                             [Kamel: [his, his, Kamel], the clan: [the clan, the clan], Saddam: [Saddam, He, his, his]]   \n",
       "3  [the massacre of Portella di Ginestra: [the massacre of Portella di Ginestra, the massacre], Giuliano: [Giuliano, Giuliano, Giuliano], a trial whi...   \n",
       "4                                                                                                      [Eddie Devane  : [Eddie Devane  , his, his, his]]   \n",
       "\n",
       "                                                                                                                                                  corefa  \\\n",
       "0                                                                                                                          [Bob Suter: [Bob Suter, His]]   \n",
       "1                                                                                                                                                   None   \n",
       "2                                                                                                           [Ali Aladhadh: [Ali Aladhadh, He, his, his]]   \n",
       "3  [Alliata and Marchesano: [Alliata and Marchesano, their], a trial which dealt with their alleged role in the event: [a trial which dealt with thei...   \n",
       "4                                                                                                                                                   None   \n",
       "\n",
       "                                                         corefb  \n",
       "0                     [Dehner's uncles: [Dehner's uncles, His]]  \n",
       "1                                                          None  \n",
       "2                              [Saddam: [Saddam, He, his, his]]  \n",
       "3  [Pisciotta: [Pisciotta, he], Giuliano: [Giuliano, Giuliano]]  \n",
       "4                                                          None  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the updated text\n",
    "#data_clean = pd.DataFrame(datatest.apply(round1))\n",
    "#data_clean\n",
    "\n",
    "# Use .apply to save the new column if we'd like\n",
    "#datatest = pd.DataFrame(test.Text.apply(round1))\n",
    "datatest['clear'] = datatest.apply(clear, axis=1)\n",
    "datatest['coref'] = datatest.apply(coref, axis=1)\n",
    "datatest['corefa'] = datatest.apply(corefa, axis=1)\n",
    "datatest['corefb'] = datatest.apply(corefb, axis=1)\n",
    "datatest[['coref', 'corefa', 'corefb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth =150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading NLP libraries\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlp_features(s, w):\n",
    "    doc = nlp(str(s))\n",
    "    tokens = pd.DataFrame([[token.text, token.dep_] for token in doc], columns=['text', 'dep'])\n",
    "    return len(tokens[((tokens['text']==w) & (tokens['dep']=='poss'))])\n",
    "\n",
    "train['A-poss'] = train['Text'].map(lambda x: get_nlp_features(x, 'anoun'))\n",
    "train['B-poss'] = train['Text'].map(lambda x: get_nlp_features(x, 'bnoun'))\n",
    "test['A-poss'] = test['Text'].map(lambda x: get_nlp_features(x, 'anoun'))\n",
    "test['B-poss'] = test['Text'].map(lambda x: get_nlp_features(x, 'bnoun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A_Noun</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B_Noun</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>Upon their acceptance into the Kontinental Hoc...</td>\n",
       "      <td>His</td>\n",
       "      <td>383</td>\n",
       "      <td>Bob Suter</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "      <td>Dehner</td>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-2</td>\n",
       "      <td>Between the years 1979-1981, River won four lo...</td>\n",
       "      <td>him</td>\n",
       "      <td>430</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>353</td>\n",
       "      <td>True</td>\n",
       "      <td>Alfredo Di St*fano</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-3</td>\n",
       "      <td>Though his emigration from the country has aff...</td>\n",
       "      <td>He</td>\n",
       "      <td>312</td>\n",
       "      <td>Ali Aladhadh</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>Saddam</td>\n",
       "      <td>295</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test-4</td>\n",
       "      <td>At the trial, Pisciotta said: ``Those who have...</td>\n",
       "      <td>his</td>\n",
       "      <td>526</td>\n",
       "      <td>Alliata</td>\n",
       "      <td>377</td>\n",
       "      <td>False</td>\n",
       "      <td>Pisciotta</td>\n",
       "      <td>536</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test-5</td>\n",
       "      <td>It is about a pair of United States Navy shore...</td>\n",
       "      <td>his</td>\n",
       "      <td>406</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>421</td>\n",
       "      <td>True</td>\n",
       "      <td>Rock Reilly</td>\n",
       "      <td>559</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Chasers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Text Pronoun  \\\n",
       "0  test-1  Upon their acceptance into the Kontinental Hoc...     His   \n",
       "1  test-2  Between the years 1979-1981, River won four lo...     him   \n",
       "2  test-3  Though his emigration from the country has aff...      He   \n",
       "3  test-4  At the trial, Pisciotta said: ``Those who have...     his   \n",
       "4  test-5  It is about a pair of United States Navy shore...     his   \n",
       "\n",
       "   Pronoun-offset        A_Noun  A-offset  A-coref              B_Noun  \\\n",
       "0             383     Bob Suter       352    False              Dehner   \n",
       "1             430        Alonso       353     True  Alfredo Di St*fano   \n",
       "2             312  Ali Aladhadh       256     True              Saddam   \n",
       "3             526       Alliata       377    False           Pisciotta   \n",
       "4             406         Eddie       421     True         Rock Reilly   \n",
       "\n",
       "   B-offset  B-coref                                             URL  \n",
       "0       366     True      http://en.wikipedia.org/wiki/Jeremy_Dehner  \n",
       "1       390    False    http://en.wikipedia.org/wiki/Norberto_Alonso  \n",
       "2       295    False           http://en.wikipedia.org/wiki/Aladhadh  \n",
       "3       536     True  http://en.wikipedia.org/wiki/Gaspare_Pisciotta  \n",
       "4       559    False            http://en.wikipedia.org/wiki/Chasers  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Upon their acceptance into the Kontinental Hockey League, Dehner left Finland to sign a contract in Germany with EHC M*nchen of the DEL on June 18, 2014. After capturing the German championship with the M*nchen team in 2016, he left the club and was picked up by fellow DEL side EHC Wolfsburg in July 2016. Former NHLer Gary Suter and Olympic-medalist Bob Suter are Dehner's uncles. His cousin is Minnesota Wild's alternate captain Ryan Suter.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[he: [he, His]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding nueral coref\n",
    "import spacy\n",
    "nlp = spacy.load('en_coref_md')\n",
    "\n",
    "#doc = nlp(str(train['Text'][0]))\n",
    "\n",
    "doc._.has_coref\n",
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Kamel: [his, his, Kamel],\n",
       " the clan: [the clan, the clan],\n",
       " Saddam: [Saddam, He, his, his]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u\"Though his emigration from the country has affected his leadership status, Kamel is still a respected elder of the clan. After the fall of Hussien's regime, many considered Dr. Ali Aladhadh a candidate to lead the clan. A contributor to Iraq's liberation, Ali Aladhadh and a long time oppose to Saddam's regime. He was ambushed with his pregnant wife on his way to the hospital in 2006 by Iraqi insurgents.\")\n",
    "\n",
    "#doc._.has_coref\n",
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Saddam: [Saddam, He, his, his]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"Though his emigration from the country has affected his leadership status, Kamel is still a respected elder of the clan. After the fall of Hussien's regime, many considered Dr. Ali Aladhadh a candidate to lead the clan. A contributor to Iraq's liberation, Ali Aladhadh and a long time oppose to Saddam's regime. He was ambushed with his pregnant wife on his way to the hospital in 2006 by Iraqi insurgents.\"\n",
    "#word.find(\"Dehner\")\n",
    "#word[word.find(\"Dehner\"):]\n",
    "\n",
    "doc = nlp(word[295:])\n",
    "\n",
    "doc._.has_coref\n",
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Though though ADP IN mark Xxxxx True False\n",
      "his -PRON- ADJ PRP$ poss xxx True True\n",
      "emigration emigration NOUN NN nsubj xxxx True False\n",
      "from from ADP IN prep xxxx True True\n",
      "the the DET DT det xxx True True\n",
      "country country NOUN NN pobj xxxx True False\n",
      "has have VERB VBZ aux xxx True True\n",
      "affected affect VERB VBN advcl xxxx True False\n",
      "his -PRON- ADJ PRP$ poss xxx True True\n",
      "leadership leadership NOUN NN compound xxxx True False\n",
      "status status NOUN NN dobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "Kamel kamel PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ ROOT xx True True\n",
      "still still ADV RB advmod xxxx True True\n",
      "a a DET DT det x True True\n",
      "respected respected ADJ JJ amod xxxx True False\n",
      "elder elder NOUN NN attr xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "clan clan NOUN NN pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "After after ADP IN prep Xxxxx True False\n",
      "the the DET DT det xxx True True\n",
      "fall fall NOUN NN pobj xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "Hussien hussien PROPN NNP poss Xxxxx True False\n",
      "'s 's PART POS case 'x False False\n",
      "regime regime NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "many many ADJ JJ nsubj xxxx True True\n",
      "considered consider VERB VBN ROOT xxxx True False\n",
      "Dr. dr. PROPN NNP compound Xx. False False\n",
      "Ali ali PROPN NNP compound Xxx True False\n",
      "Aladhadh aladhadh PROPN NNP nsubj Xxxxx True False\n",
      "a a DET DT det x True True\n",
      "candidate candidate NOUN NN ccomp xxxx True False\n",
      "to to PART TO aux xx True True\n",
      "lead lead VERB VB acl xxxx True False\n",
      "the the DET DT det xxx True True\n",
      "clan clan NOUN NN dobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "A a DET DT det X True False\n",
      "contributor contributor NOUN NN nsubj xxxx True False\n",
      "to to ADP IN prep xx True True\n",
      "Iraq iraq PROPN NNP poss Xxxx True False\n",
      "'s 's PART POS case 'x False False\n",
      "liberation liberation NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "Ali ali PROPN NNP compound Xxx True False\n",
      "Aladhadh aladhadh PROPN NNP appos Xxxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "a a DET DT det x True True\n",
      "long long ADJ JJ amod xxxx True False\n",
      "time time NOUN NN conj xxxx True False\n",
      "oppose oppose VERB VB ROOT xxxx True False\n",
      "to to ADP IN prep xx True True\n",
      "Saddam saddam PROPN NNP poss Xxxxx True False\n",
      "'s 's PART POS case 'x False False\n",
      "regime regime NOUN NN pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "He -PRON- PRON PRP nsubjpass Xx True False\n",
      "was be VERB VBD auxpass xxx True True\n",
      "ambushed ambush VERB VBN ROOT xxxx True False\n",
      "with with ADP IN prep xxxx True True\n",
      "his -PRON- ADJ PRP$ poss xxx True True\n",
      "pregnant pregnant ADJ JJ amod xxxx True False\n",
      "wife wife NOUN NN pobj xxxx True False\n",
      "on on ADP IN prep xx True True\n",
      "his -PRON- ADJ PRP$ poss xxx True True\n",
      "way way NOUN NN pobj xxx True False\n",
      "to to ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "hospital hospital NOUN NN pobj xxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "2006 2006 NUM CD pobj dddd False False\n",
      "by by ADP IN agent xx True True\n",
      "Iraqi iraqi ADJ JJ amod Xxxxx True False\n",
      "insurgents insurgent NOUN NNS pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(word)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features3(df):\n",
    "    doc = nlp(word)\n",
    "    doc._.has_coref\n",
    "    doc._.coref_clusters\n",
    "    \n",
    "    doc = nlp(str(s))\n",
    "    tokens = pd.DataFrame([[token.text, token.dep_] for token in doc], columns=['text', 'dep'])\n",
    "    return len(tokens[((tokens['text']==w) & (tokens['dep']=='poss'))])\n",
    "    return(df)\n",
    "\n",
    "op = get_features3(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = train['Text'].apply(lambda x: [wrd for wrd in x.split() if wrd.isupper()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'A-coref':'A', 'B-coref':'B'})\n",
    "train['A'] = train['A'].astype(int)\n",
    "train['B'] = train['B'].astype(int)\n",
    "train['NEITHER'] = 1.0 - (train['A'] + train['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['B_Noun'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_features2(df):\n",
    "    doc = nlp(str(s))\n",
    "    tokens = pd.DataFrame([[token.text, token.dep_] for token in doc], columns=['text', 'dep'])\n",
    "    return len(tokens[((tokens['text']==w) & (tokens['dep']=='poss'))])\n",
    "    return(df)\n",
    "\n",
    "train = get_features2(train)\n",
    "test = get_features2(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features3(trainDF):\n",
    "\n",
    "    return(trainDF)\n",
    "\n",
    "train = get_features3(train)\n",
    "test = get_features3(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "col = ['char_count','word_count','word_density','punctuation_count','title_word_count','upper_case_word_count','section_min', 'Pronoun-offset2', 'A_count', 'B_count', 'A-offset2', 'B-offset2', 'section_max', 'A-poss', 'B-poss', 'A-dist', 'B-dist']\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train[col].fillna(-1), train[['A', 'B', 'NEITHER']], test_size=0.2, random_state=1)\n",
    "x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multiclass.OneVsRestClassifier(ensemble.RandomForestClassifier(max_depth = 7, n_estimators=1000, random_state=33))\n",
    "# model = multiclass.OneVsRestClassifier(ensemble.ExtraTreesClassifier(n_jobs=-1, n_estimators=100, random_state=33))\n",
    "\n",
    "# param_dist = {'objective': 'binary:logistic', 'max_depth': 1, 'n_estimators':1000, 'num_round':1000, 'eval_metric': 'logloss'}\n",
    "# model = multiclass.OneVsRestClassifier(xgb.XGBClassifier(**param_dist))\n",
    "\n",
    "model.fit(x1, y1)\n",
    "print('log_loss', metrics.log_loss(y2, model.predict_proba(x2)))\n",
    "model.fit(train[col].fillna(-1), train[['A', 'B', 'NEITHER']])\n",
    "results = model.predict_proba(test[col])\n",
    "test['A'] = results[:,0]\n",
    "test['B'] = results[:,1]\n",
    "test['NEITHER'] = results[:,2]\n",
    "test[['ID', 'A', 'B', 'NEITHER']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(x1, x2, y1, y2):\n",
    "    model.fit(x1, y1)\n",
    "    log_loss = metrics.log_loss(y2, model.predict_proba(x2))\n",
    "    print('log_loss', log_loss)\n",
    "    return log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build step forward feature selection\n",
    "sfs1 = sfs(model,\n",
    "           k_features=5,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['B_count', 'A-poss', 'B-poss']\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train[col].fillna(-1), train[['A', 'B', 'NEITHER']], test_size=0.2, random_state=1)\n",
    "\n",
    "model.fit(x1, y1)\n",
    "print('log_loss', metrics.log_loss(y2, model.predict_proba(x2)))\n",
    "model.fit(train[col].fillna(-1), train[['A', 'B', 'NEITHER']])\n",
    "results = model.predict_proba(test[col])\n",
    "test['A'] = results[:,0]\n",
    "test['B'] = results[:,1]\n",
    "test['NEITHER'] = results[:,2]\n",
    "test[['ID', 'A', 'B', 'NEITHER']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['B_count', 'A-poss', 'B-poss']\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train[col].fillna(-1), train[['A', 'B', 'NEITHER']], test_size=0.2, random_state=1)\n",
    "\n",
    "#model = multiclass.OneVsRestClassifier(ensemble.ExtraTreesClassifier(n_jobs=-1, n_estimators=100, random_state=33))\n",
    "\n",
    "param_dist = {'objective': 'binary:logistic', 'max_depth': 1, 'n_estimators':1000, 'num_round':1000, 'eval_metric': 'logloss'}\n",
    "model = multiclass.OneVsRestClassifier(xgb.XGBClassifier(**param_dist))\n",
    "\n",
    "model.fit(x1, y1)\n",
    "print('log_loss', metrics.log_loss(y2, model.predict_proba(x2)))\n",
    "model.fit(train[col].fillna(-1), train[['A', 'B', 'NEITHER']])\n",
    "\n",
    "results = model.predict_proba(test[col])\n",
    "test['A'] = results[:,0]\n",
    "test['B'] = results[:,1]\n",
    "test['NEITHER'] = results[:,2]\n",
    "test[['ID', 'A', 'B', 'NEITHER']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Let's pickle it for later use\n",
    "train.to_pickle(\"train.pkl\")\n",
    "test.to_pickle(\"test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
