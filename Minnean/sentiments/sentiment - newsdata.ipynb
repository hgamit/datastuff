{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150, 3)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "from google.cloud.language_v1.types import AnalyzeEntitiesRequest\n",
    "\n",
    "\n",
    "def sample_analyze_sentiment(dataset):\n",
    "    \"\"\"\n",
    "    Analyzing Sentiment in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    #array = np.array([],[]);\n",
    "    n=len(dataset['newsdata'])\n",
    "    \n",
    "    df = pd.DataFrame(data=np.zeros((n,22)),\n",
    "                      columns = ['score','magnitude',\n",
    "                                 'china','chinasalience',\n",
    "                                 'brazil','brazilsalience',\n",
    "                                 'argentina','argentinasalience',\n",
    "                                 'soybean','soybeanssalience',\n",
    "                                 'tarrif','ttrrifsalience',\n",
    "                                 'trade','tradesalience',\n",
    "                                 'pork','porksalience',\n",
    "                                 'weather','weathersalience',\n",
    "                                 'trump','trumpsalience',\n",
    "                                 'disease','diseasesalience'\n",
    "                                ]);\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        \n",
    "        language = \"en\"\n",
    "        document = {\"content\": dataset['newsdata'][i], \"type\": type_, \"language\": language}\n",
    "        encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "        rsentiment = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
    "        response = client.analyze_entities(document, encoding_type=encoding_type)\n",
    "        \n",
    "        # Get overall sentiment of the input document\n",
    "        #print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
    "        #print(u\"Document sentiment magnitude: {}\".format(response.document_sentiment.magnitude))\n",
    "        df.iloc[i,0]=rsentiment.document_sentiment.score\n",
    "        df.iloc[i,1]=rsentiment.document_sentiment.magnitude\n",
    "        \n",
    "        for entity in response.entities:\n",
    "            \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'china').ratio()\n",
    "            if(similarity>0.8): \n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,2]+=1\n",
    "                df.iloc[i,3]=entity.salience\n",
    "                \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'brazil').ratio()\n",
    "            if(similarity>0.8): \n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,4]+=1\n",
    "                df.iloc[i,5]=entity.salience\n",
    "                \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'argentina').ratio()\n",
    "            if(similarity>0.8): \n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,6]+=1\n",
    "                df.iloc[i,7]=entity.salience\n",
    "            \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'soybean').ratio()\n",
    "            if(similarity>0.8):\n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,8]+=1\n",
    "                df.iloc[i,9]=entity.salience\n",
    "                \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'tarrif').ratio()\n",
    "            if(similarity>0.8):\n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,10]+=1\n",
    "                df.iloc[i,11]=entity.salience\n",
    "                \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'trade').ratio()\n",
    "            if(similarity>0.8):\n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,12]+=1\n",
    "                df.iloc[i,13]=entity.salience\n",
    "                \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'pork').ratio()\n",
    "            if(similarity>0.8):\n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,14]+=1\n",
    "                df.iloc[i,15]=entity.salience\n",
    "                \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'weather').ratio()\n",
    "            if(similarity>0.8):\n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,16]+=1\n",
    "                df.iloc[i,17]=entity.salience\n",
    "                \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'trump').ratio()\n",
    "            if(similarity>0.8):\n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,18]+=1\n",
    "                df.iloc[i,19]=entity.salience\n",
    "                \n",
    "            similarity=0\n",
    "            entityname =entity.name\n",
    "            similarity = SequenceMatcher(None, entityname.lower(), 'disease').ratio()\n",
    "            if(similarity>0.8):\n",
    "                for mention in entity.mentions:\n",
    "                    df.iloc[i,20]+=1\n",
    "                df.iloc[i,21]=entity.salience\n",
    "            \n",
    "        # Get the language of the text, which will be the same as\n",
    "        # the language specified in the request or, if not specified,\n",
    "        # the automatically-detected language.\n",
    "        #print(u\"Language of the text: {}\".format(response.language))\n",
    "        \n",
    "        \n",
    "        \n",
    "    return df;\n",
    "        \n",
    "    \n",
    "dataset = pd.read_csv('./agri.csv',nrows=1200)\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "df = sample_analyze_sentiment(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([dataset, df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"agrisentiment3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsheadline</th>\n",
       "      <th>newstime</th>\n",
       "      <th>newsdata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1145</td>\n",
       "      <td>Brazil soybean planting rises, Parana lag rais...</td>\n",
       "      <td>21 Oct 2019 | Thomas Hughes</td>\n",
       "      <td>The pace of plantings for Brazil's soybean cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1146</td>\n",
       "      <td>China soybean crush rises 8%: CNGOIC</td>\n",
       "      <td>18 Jul 2019 | Johnny Huang</td>\n",
       "      <td>China's soybean crush rose 8% last week, accor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1147</td>\n",
       "      <td>Price falls provoke private export sales spurt...</td>\n",
       "      <td>12 Dec 2017 | Tim Worledge</td>\n",
       "      <td>Decemberâ€™s World Agriculture Supply and Demand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1148</td>\n",
       "      <td>Chinese soymeal stocks 13% down year-on-year</td>\n",
       "      <td>1 Mar 2018 | Andy Allan, Rei Geyssens, Johnny ...</td>\n",
       "      <td>Soymeal stocks in China stand at 720,000 mt, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1149</td>\n",
       "      <td>Presidential signature ends rebate uncertainty...</td>\n",
       "      <td>30 Aug 2018 | Rei Geyssens</td>\n",
       "      <td>Ukrainian President Petro Poroshenko signed a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           newsheadline  \\\n",
       "1145  Brazil soybean planting rises, Parana lag rais...   \n",
       "1146               China soybean crush rises 8%: CNGOIC   \n",
       "1147  Price falls provoke private export sales spurt...   \n",
       "1148       Chinese soymeal stocks 13% down year-on-year   \n",
       "1149  Presidential signature ends rebate uncertainty...   \n",
       "\n",
       "                                               newstime  \\\n",
       "1145                        21 Oct 2019 | Thomas Hughes   \n",
       "1146                         18 Jul 2019 | Johnny Huang   \n",
       "1147                         12 Dec 2017 | Tim Worledge   \n",
       "1148  1 Mar 2018 | Andy Allan, Rei Geyssens, Johnny ...   \n",
       "1149                         30 Aug 2018 | Rei Geyssens   \n",
       "\n",
       "                                               newsdata  \n",
       "1145  The pace of plantings for Brazil's soybean cro...  \n",
       "1146  China's soybean crush rose 8% last week, accor...  \n",
       "1147  Decemberâ€™s World Agriculture Supply and Demand...  \n",
       "1148  Soymeal stocks in China stand at 720,000 mt, d...  \n",
       "1149  Ukrainian President Petro Poroshenko signed a ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
