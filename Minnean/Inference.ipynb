{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T02:38:44.439642Z",
     "start_time": "2019-11-04T02:38:43.649654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 7)\n"
     ]
    }
   ],
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "#https://www.youtube.com/watch?v=zwqwlR48ztQ\n",
    "\n",
    "# Recurrent Neural Network\n",
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the training set\n",
    "dataset_train = pd.read_csv('./marketdata/zsh20.csv')\n",
    "                            #soybean/zsk20_daily_price-history-10-25-2019.csv')\n",
    "#dataset_train = dataset_train[dataset_train[\"Volume\"] != 0]\n",
    "\n",
    "dataset_train.Time = pd.to_datetime(dataset_train.Time.str.replace('D', 'T'))\n",
    "dataset_train = dataset_train.sort_values('Time')\n",
    "dataset_train.set_index('Time', inplace=True)\n",
    "print(dataset_train.shape)\n",
    "training_set = dataset_train.iloc[:, 1:8].values\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (-1, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T02:39:16.047618Z",
     "start_time": "2019-11-04T02:39:16.007678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a data structure with 15 timesteps and 1 output - we use last 15 prices to predict next. \n",
    "#This takes data from 15th row onwards\n",
    "X_whole = []\n",
    "y_whole = []\n",
    "\n",
    "X_whole_vchange = []\n",
    "y_whole_vchange = []\n",
    "\n",
    "\n",
    "X_whole_wvap = []\n",
    "y_whole_wvap = []\n",
    "\n",
    "sequence_size = 1\n",
    "for i in range(sequence_size, len(training_set_scaled)):\n",
    "    X_whole = np.append(X_whole, training_set_scaled[i-sequence_size:i, 2])\n",
    "    #X_whole = np.append(X_whole, training_set_scaled[i, 6])\n",
    "    #X_whole = np.append(X_whole, training_set_scaled[i, 7])\n",
    "    vwap = 0\n",
    "    vol = 0\n",
    "    vchg = 0\n",
    "    for j in range(sequence_size):\n",
    "        if (j+i<training_set_scaled.shape[0]):\n",
    "            vwap += (((np.sum(training_set_scaled[j+i, 0:3]))/3) * training_set_scaled[j+i, 4])\n",
    "            vchg += (((training_set_scaled[j+i, 3])) * training_set_scaled[j+i, 4])\n",
    "            vol += training_set_scaled[j+i, 4]\n",
    "    #if vwap !=0  and vol != 0:\n",
    "    X_whole = np.append(X_whole, vwap/vol)\n",
    "    X_whole = np.append(X_whole, vchg/vol)\n",
    "    y_whole.append(training_set_scaled[i, 0])\n",
    "\n",
    "sz = training_set_scaled.shape[0]-sequence_size\n",
    "X_whole, y_whole = np.array(X_whole.reshape(sz,sequence_size+2)), np.array(y_whole)\n",
    "\n",
    "\n",
    "for i in range(sequence_size, len(X_whole)):\n",
    "    X_whole_wvap = np.append(X_whole_wvap,X_whole[i-sequence_size:i, sequence_size])\n",
    "    X_whole_wvap = np.append(X_whole_wvap,X_whole[i, 0])\n",
    "    X_whole_wvap = np.append(X_whole_wvap,X_whole[i, sequence_size+1])\n",
    "    y_whole_wvap.append(X_whole[i, sequence_size])\n",
    "    \n",
    "    X_whole_vchange = np.append(X_whole_vchange,X_whole[i-sequence_size:i, sequence_size+1])\n",
    "    X_whole_vchange = np.append(X_whole_vchange,X_whole[i, 0])\n",
    "    X_whole_vchange = np.append(X_whole_vchange,X_whole[i, sequence_size])\n",
    "    y_whole_vchange.append(X_whole[i, sequence_size+1])\n",
    "\n",
    "sz1 = X_whole.shape[0]-sequence_size\n",
    "X_whole_wvap, y_whole_wvap = np.array(X_whole_wvap.reshape(sz1,sequence_size+2)), np.array(y_whole_wvap)\n",
    "X_whole_vchange, y_whole_vchange = np.array(X_whole_vchange.reshape(sz1,sequence_size+2)), np.array(y_whole_vchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on new data\n",
    "xw=X_whole[-1:]\n",
    "xw=xw.reshape(1,-1)\n",
    "xw=np.reshape(xw,(xw.shape[0], xw.shape[1], 1))\n",
    "\n",
    "xwvap = X_whole_wvap[-1:]\n",
    "xwvap=xwvap.reshape(1,-1)\n",
    "xwvap=np.reshape(xwvap,(xwvap.shape[0], xwvap.shape[1], 1))\n",
    "\n",
    "xvchange=X_whole_vchange[-1:]\n",
    "xvchange=xvchange.reshape(1,-1)\n",
    "xvchange=np.reshape(xvchange,(xvchange.shape[0], xvchange.shape[1], 1))\n",
    "\n",
    "y_pred_w = []\n",
    "\n",
    "num_of_pred = 2\n",
    "\n",
    "for i in range(0,num_of_pred):\n",
    "    \n",
    "    y_pred1=regressor.predict(xw)\n",
    "    test_data = np.zeros(shape=(len(y_pred1), 6) )\n",
    "    test_data[:,2] = y_pred1\n",
    "    y_transformed  = sc.inverse_transform(test_data)[:,2]\n",
    "    y_pred_w = np.append(y_pred_w,y_transformed)\n",
    "    \n",
    "    y_pred2=regressorWvap.predict(xwvap)\n",
    "    \n",
    "    y_pred3=regressorVchange.predict(xvchange)\n",
    "    \n",
    "    print(y_pred1,y_pred2,y_pred3)\n",
    "    \n",
    "    for j in range(sequence_size):\n",
    "        xw[:,:,j]=xw[:,j+1]\n",
    "     \n",
    "    \n",
    "    #xw[:,sequence_size-1]=y_pred1\n",
    "    #xw[:,sequence_size]=y_pred2\n",
    "    #xw[:,sequence_size+1]=y_pred3\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
